<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>My Web Scraping Journey: From Beginner to Data Ninja</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">ShCyberNin</a>
					</header>

				<!-- Nav -->
				<nav id="nav">
					<ul class="links">
						<li class="active"><a href="index.html">Shahril's Space</a></li>
						<li><a href="https://raw.githubusercontent.com/ShCyberNin/ShCyberNin.github.io/main/Resume.pdf" download>Download my resume</a></li>
					</ul>
					<ul class="icons">
						<li><a href="https://github.com/ShCyberNin" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						<li><a href="https://www.linkedin.com/in/mdshahrilcyber" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
					</ul>
				</nav>

                <!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<h1>My Web Scraping Journey:<br />
                                    From Beginner to Data Ninja</h1>
							<section>
								<p>Hello! Today, I'm excited to share my journey into learning basic web scraping with Python. Over the past week, I've dived headfirst into this fascinating field, learning valuable skills and completing simple but exciting projects along the way.</p>	
								<h3>What is Web Scraping?</h3>
                                <p>Web scraping is the process of extracting data from websites. It involves using automated tools to retrieve information from web pages and then organizing that data for analysis or other purposes. With web scraping, you can gather data such as text, images, prices, or any other information available on the internet.</p>
								<p>By using Python libraries like BeautifulSoup and Playwright, I was able to navigate through web pages, locate specific elements, and extract the data I needed for my projects. This skill opened up a world of possibilities for me, allowing me to gather insights from various online sources quickly and efficiently.</p>								
							</section>

                            <section>
                                <h3>Learning the Basics</h3>
                                <p>My journey began with learning the basics of Python programming from YouTube, Reddit, GitHub, and also ChatGPT ðŸ˜‰. Armed with this knowledge, I delved into the world of web scraping, familiarizing myself with popular libraries like BeautifulSoup and Playwright. These tools proved to be invaluable as I learned to extract data from web pages effortlessly.</p>
                            </section>
                            
                            <section>
                                <h3>Project 1: Beginner Web Scraping</h3>
                                <p>To solidify my understanding, I embarked on my first project: scraping quotes from a popular website. This project served as a perfect introduction to web scraping techniques, allowing me to practice extracting text content and saving it to a CSV file.</p>
                                <p>Below is a screenshot of the output of running  the python script and the csv file created.</p>
                                <div style="text-align: center;">
                                    <a href="#" class="image fit"></a><img src="screenshot_quotes.png" alt="Screenshot of the output of running the Python script." /></a>
                                    <figcaption>Figure 1: Screenshot of the output of running the Python script.</figcaption>
                                </div>
                                <div style="text-align: center;">
                                    <a href="#" class="image fit"></a><img src="screenshot_quotes.png" alt="Screenshot of the output of running the Python script." /></a>
                                    <figcaption>Figure 2: screenshot of the CSV file created.</figcaption>
                                </div>

                                <p>For this project, I utilized Python along with the BeautifulSoup and requests libraries. </br>Let me break down the code for you:</p>
                                <div style="text-align: left;">
                                <pre><code># Import necessary libraries
from bs4 import BeautifulSoup  # For parsing HTML
import requests  # For fetching web pages
import csv  # For writing data to a CSV file
                                   
# Send an HTTP GET request to the specified URL
page_to_scrape = requests.get("https://quotes.toscrape.com")
                                    
# Parse the HTML content of the page
soup = BeautifulSoup(page_to_scrape.text, "html.parser")
                                    
# Find all quotes and authors on the page
quotes = soup.findAll("span", attrs={"class": "text"})
authors = soup.findAll("small", attrs={"class": "author"})
                                    
# Open a CSV file in write mode
file = open("scraped_quotes.csv", "w")
                                    
# Create a CSV writer object
writer = csv.writer(file)
                                    
# Write the header row to the CSV file
writer.writerow(["QUOTES", "AUTHORS"])
                                    
# Iterate over quotes and authors and write them to the CSV file
for quote, author in zip(quotes, authors):
# Print the quote and author to the console
print(quote.text + " - " + author.text)
# Write the quote and author to the CSV file
writer.writerow([quote.text, author.text])
                                    
# Close the CSV file
file.close()
                                    
# Print a confirmation message
print("Scraped quotes have been saved to scraped_quotes.csv")
</code></pre>
                            </div>
                        </section>
                        
                        <div class="explanation">
                            <h3>Explanation:</h3>
                            <ol>
                                <li>
                                    <p><strong>Import Libraries:</strong> We import BeautifulSoup for parsing HTML, requests for fetching web pages, and csv for writing data to a CSV file.</p>
                                </li>
                                <li>
                                    <p><strong>Fetch the Web Page:</strong> We use the requests.get() method to send an HTTP GET request to the specified URL, which in this case is "https://quotes.toscrape.com". The response is stored in the variable page_to_scrape.</p>
                                </li>
                                <li>
                                    <p><strong>Scrape Quotes and Authors:</strong> We use BeautifulSoup's findAll() method to locate all <code>&lt;span&gt;</code> elements with the class "text" (quotes) and <code>&lt;small&gt;</code> elements with the class "author" (authors). The scraped quotes and authors are stored in the quotes and authors variables, respectively.</p>
                                </li>
                                <li>
                                    <p><strong>Write Quotes to CSV File:</strong> We open a CSV file named "scraped_quotes.csv" in write mode using open() function. We use csv.writer() to create a CSV writer object. We write the header row containing "QUOTES" and "AUTHORS" using writer.writerow(). Using a for loop and zip(), we iterate over the quotes and authors simultaneously and write each quote and its corresponding author to the CSV file.</p>
                                </li>
                            </ol>
                        </div>
                        <div style="text-align: center;">
                            <a href="#" class="image fit"></a><img src="screenshot_quotes.png" alt="Screenshot of the output of running the Python script." /></a>
                            <figcaption>Figure 2: screenshot of the CSV file created.</figcaption>
                        </div>
                        <div>
                        <p>This figure 2 screenshot showcases the result of the code, where quotes and authors have been successfully scraped and saved to a CSV file named "scraped_quotes.csv".</p>   
                        </div>
                    </section>

                    
                            


                
                <!-- Footer -->
                <footer id="footer">
                    <section class="split contact">
                        <section>
                            <h3>Email</h3>
                            <p><a href="#">md.shahril1991@gmail.com</a></p>
                        </section>
                        <section>
                            <h3>Social</h3>
                            <ul class="icons alt">
                                <li><a href="https://github.com/ShCyberNin" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
                            <li><a href="https://www.linkedin.com/in/mdshahrilcyber" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
                            </ul>
                        </section>
                    </section>
                </footer>
                </div>

                <!-- Scripts -->
                <script src="assets/js/jquery.min.js"></script>
                <script src="assets/js/jquery.scrollex.min.js"></script>
                <script src="assets/js/jquery.scrolly.min.js"></script>
                <script src="assets/js/browser.min.js"></script>
                <script src="assets/js/breakpoints.min.js"></script>
                <script src="assets/js/util.js"></script>
                <script src="assets/js/main.js"></script>

                </body>
                </html>